{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\n\n# ---------- parameters ----------\nn_train = 50_000\nn_test  = 50_000\nmu_func = lambda x: 50 - x          # conditional mean\nsigma2  = 4                         # conditional variance\nxmin, xmax = 0.0, 30.0              # support of X\n\n# ---------- data generation ----------\nrng = np.random.default_rng(seed=42)\nX_train = rng.uniform(xmin, xmax, n_train)\nX_test  = rng.uniform(xmin, xmax, n_test)\n\ndef sample_y(x):\n    return rng.normal(loc=mu_func(x), scale=np.sqrt(sigma2))\n\nY_train = sample_y(X_train)\nY_test  = sample_y(X_test)\n\n# ---------- estimators ----------\ndef f_star(x):            # Bayes predictor\n    return mu_func(x)\n\nYhat_star_test = f_star(X_test)\n\nybar_train = Y_train.mean()\ndef f_tilde(x):           # simple constant estimator\n    return np.full_like(x, ybar_train)\n\nYhat_tilde_test = f_tilde(X_test)\n\n# ---------- empirical risks ----------\nmse_star  = np.mean((Y_test  - Yhat_star_test)  ** 2)\nmse_tilde = np.mean((Y_test  - Yhat_tilde_test) ** 2)\n\nprint(f\"Test MSE for Bayes estimator  f*:   {mse_star:.4f}\")\nprint(f\"Test MSE for competitor      f~:   {mse_tilde:.4f}\")\nprint(\"\\n(Theoretical Bayes risk is 4.0)\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-08T17:22:18.490560Z","iopub.execute_input":"2025-07-08T17:22:18.491460Z","iopub.status.idle":"2025-07-08T17:22:18.506133Z","shell.execute_reply.started":"2025-07-08T17:22:18.491427Z","shell.execute_reply":"2025-07-08T17:22:18.505297Z"}},"outputs":[{"name":"stdout","text":"Test MSE for Bayes estimator  f*:   3.9882\nTest MSE for competitor      f~:   79.0262\n\n(Theoretical Bayes risk is 4.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Because $f^\\*$ is optimal, its empirical risk converges to the Bayes risk (≈ 4).\nThe constant predictor has no access to $X$; consequently its risk equals $\\operatorname{Var}(Y)$ (≈ $\\sigma^2 + \\operatorname{Var}[\\mu(X)]$), which is strictly larger than 4, so the simulation confirms the theory.","metadata":{}}]}